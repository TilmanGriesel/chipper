# Provider (ollama or hf)
# If 'hf' is selected as the provider, an API key from Hugging Face will be required.
# Hugging Face models (hf_ models) will be used when this option is chosen.
PROVIDER=ollama

# Ollama
OLLAMA_URL=http://host.docker.internal:21240
ALLOW_MODEL_PULL=true

# Huggingface
HF_API_KEY=your-huggingface-api-key

# Embedding
EMBEDDING_MODEL_NAME=snowflake-arctic-embed2
HF_EMBEDDING_MODEL_NAME=Snowflake/snowflake-arctic-embed-l-v2.0

# Default query settings
MODEL_NAME=llama3.2
HF_MODEL_NAME=meta-llama/Llama-3.3-70B-Instruct
CONTEXT_WINDOW=8192
TEMPERATURE=0.8
SEED=0
TOP_K=5

# Elastic search
ES_URL=http://host.docker.internal:21220
ES_INDEX=default

# API settings
HOST=0.0.0.0
PORT=8000
API_KEY=EXAMPLE_API_KEY
REQUIRE_SECURE=false
DEBUG=false
SYSTEM_PROMPT_PATH=./
